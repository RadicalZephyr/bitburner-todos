* Startup/Bootstrap

** Add Karma to the bootstrap

Run Karma script on n00dles during gang bootstrap.

** Extend Karma to launch gang management script

Now that I'm probably not going to do any more runs of Bitnode 2,
we'll need to grind for negative karma to be able to create a gang,
and having the karma script launch the manager seems like an obvious
way to do it.

* Services

** Bugs

*** Fix bug in reserved changing

Right now, when we run scripts on a server with "reserved" memory
(really should be "in-use" memory), it is changing the amount of
reserved memory. This could be the source of the memory overcommit
because then it's losing track of the fact that this memory is in use.


** Improvements

*** Discovery

*** Port Allocator

*** Memory Allocator

**** Add memory pools concept

Really only need two pools conceptually (~hasCores~ and ~noCores~).

However, for the batch hacking system it would be ideal if we had a
pool for each of the 3 hacking lifecyle phases (till, sow, and
harvest).

Till and sow should ideally be on home if it's large enough, and
servers with low total RAM if not (because their batches are smaller).

Memory pooling is something that should change dynamically based on a
bunch of factors like:

- How many hosts are in each pending queue
- How much free RAM is available
- How large the chunks of free RAM are
- How large the total RAM on most servers is
- Whether we have more than one core on home

** New Services

*** Make Buy Servers script into a daemon

Need to integrate it with the rest of the system, particularly the
Memory Allocator and Task Selector. I guess Discovery could be part of
it too?

A lot of the grief of it could be mitigated by just not changing the
name...

Once the system can handle new hosts gracefully we should turn a
version of the buy-servers script into a long-running service daemon
that basically upgrades servers as the money comes in. Probably one by
one instead of in a whole batch.

*** Script launcher Service

Instead of having every script that wants to launch something bear the
RAM cost of using the `launch` script, create an actual `launch`
service and a client for using it.

Create a new CLI usage script for parsing command line arguments for
the script to be launched that uses the new `services/client/launch`.



* Batch Hacking

** General Improvement

*** Minimize RAM cost of task selector and monitor

I think these scripts are likely a little bloated right now because of
importing functions from other scripts that are meant to be run (like
harvest, sow and till), thus making it likely they are accidentally
having in APIs they are never going to use counted against their
static RAM size.

The thing to do here is probably make a new `batch/lib` folder and
make targeted lib files that only contain the minimum number of
functions actually used in multiple files.

*** Refactor port reading to use separate promise task structure?

Codex showed me that we can maybe just create a "polling function"
Promise to continually read from a port and do stuff with the result.

This would simplify the structure of the standard service daemons main
loops. Is there an advantage to it? Faster response times because
reading from the port would happen as soon as the write notifies the
reader.


** Till Script

*** Track changes to hacking skill and batch times

Cancel and restart weakening jobs once our hacking skill rises enough
that it becomes at least 10% faster to do so.

** Task Selector

*** Dynamic changes to hackLevelVelocityThreshold

On my last augment install run I ran into an interesting issue. My
hack level/hack experience multiplier was so high that my hacking
level was far above the minimum threshold for a stable hacking level
velocity that was hardcoded into the Task Selector. I made this a
config so at least the user can adjust it, but now there are so many
CONFIG values and you kind of have to know which ones affect which
behavior.

**** Document CONFIG values

Step one is documenting them and when it's useful to change them.

**** Dynamically adjust CONFIG values based on heuristics

Once I describe what I understand about when to change the various
config values, these heuristics should be built into the

*** Dynamic changes to expected value threshold

One neat thing about having the config values be writable properties
is that we can kind of treat them like global dynamic variables.

Under bitnode-first-entry conditions (with Source File 1 for base 32GB
RAM on home), there is some awkwardness with the expected value
threshold. I had it set fairly high to exclude n00dles from later in
the run when it's just not worth the threads, but early on it is
_essential_ to hack n00dles because with the amount of RAM available
trying to even sow foodnstuff can be slated to take up to 15 hours!!
That's so long!

I think we need to special case startup and if RAM is really
constrained like when you own 0 or 1 port crackers, just focus on
moving n00dles through the lifecycle. Then, once n00dles is at least
at a full-overlap 1-hack-thread batch we can start dedicating RAM
towards moving foodnstuff through the lifecycle.

The reason is at this point, hacking n00dles is basically our most
profitable thing to do with the limited RAM we have and scaling that
means getting money faster which means getting to more port crackers
and more RAM faster, which means we can till and sow other more
profitable targets much much faster.

**** Alternative

With better information about how much each harvest script is expected
to earn, we can gate launching new harvest tasks if they would earn
less than 1% of the amount we are already earning. This would prevent
spawning new tasks that are only going to provide an extremely
marginal increase in income.

Ideally, we would use improve expected value calculations (once they
are more accurate).

If we query the PID of the harvest script for the
~ns.getRunningScript(pid).onlineMoneyMade~) we could get the actual
value generated, however this information will be extremely delayed as
it takes a while to spawn the entire batch pipeline.


*** Dynamically choose scripts better

 - Kill and restart tasks that are under-resourced

OR

 - Support growing allocations [completed!]

In early bit-nodes every time you acquire a new port-cracking program,
the increased memory is greedily assigned to a task that is not
already in-progress. It would almost always (when isn't it?) be better
to increase the RAM available to the next-best task that is in
progress.

This requires a sophisticated collaboration between the Task Selector
and the tasks it has launched. This could be done using the
heartbeat. Maybe we could add the total expected time to complete the
task. More useful would be reporting that we could use more resources.


*** Segment RAM to different task types

This might be more a product of how much time it took me to get the
system working again under low-RAM conditions and the fact that I
fixed things in phase order (till, sow, harvest) means that a lot of hosts
were ready to start harvesting when I got the manager working again.

But right now, harvesting jobs can easily starve the tilling and
sowing jobs of money. Especially since harvesting jobs are the most
easily scalable. The current behavior is that my harvesting jobs are
scaling all the way up to hacking 50% of the target's money, which is
a lot of threads. This leaves no room for tilling or sowing new
targets.

Instead of just giving all memory to harvesting, we should segment the
free memory. Or perhaps just use a less greedy strategy?

Maybe we want to allocate to tilling and sowing first, but try and
time it so that they will be ready by the time we have the level to
target that host?

*** Handle the case where computed batch size is greater than any server has available

There's a very peculiar edge failure case in the relative lack of
coordination between the task selector and the harvest scripts. It
arises when the total free RAM in the system is large relative to the
largest free chunk of RAM (i.e. the maximum total RAM size of any
server). The task selector then naively launches a harvest script with
a `--max-ram` parameter that the `harvest` script then computes can
fit a batch size that is larger than the largest servers.

For instance, this just happened to me with:

- 1TB home RAM
- 25x1TB servers
- 5 port crackers, and ~398 hack level
- ~maxHackPercent~ == 0.2 (20%)

The total RAM is somewhere around ~27TB of RAM, which the harvest
script then concluded it could fit a full-overlap set of batches of
+1TB batches, so the allocation failed.

Clearly, there is a critical piece of information missing in this
decision making process, the maximum chunk size. I think the
`MemoryAllocator` should probably be changed to return a
`maxChunkSize` field, or perhaps a more detailed breakdown of the
available chunk sizes. This way, the task allocator and the harvest
script can make more informed choices about what batch size they try
to create.

* Stocks


* Singularity

** After-install script

If we have the Cashroot starterkit (+$1m)

 - Buy ToR Router
 - Go to Volhaven
 - Study Algorithms
 - After hacking level stabilizes (rate slows down to <1 or
   something), run ~start.ts~ script

** New Script for Collecting Augments

Basically, a script that loops, looks at the page for a "Faction
Augments" menu, then records all the information it can scrape.

It would display these unpurchased augments in reverse cost order
(most expensive at the top) to assist in buying augments in the
correct order.

*** Bonus features

 - Track when the price multiplier changes and change stored prices accordingly
 - Compare to player's money and display in red when too expensive
 - Also display an estimated time to afford based on rate of money gain
 - Implement iterating through all faction augments page automatically

* Hacknet

** Buy Hacknet Script ignores `--return-time`

It always seems to get to net positive too fast. That might be because
I'm  extremely late in the Bitnode right now and my multipliers are
absurdly high. It would be weird if the Hacknet formulas didn't take
into account the multipliers though right?


* Gang

** Boss Improvements

*** Ascension Threshold should be per member based on ascMult

The current method doesn't help newer users catch up to older ones
with high multipliers except when the high-level ones hit a breakpoint
where they no longer need to train at all.

This is partially because the amount of time we should train a member
is actually relative to their level. Also, I think my intuition was
right that the ascension multiplier threshold needs to go down as our
total multiplier gets higher. It looks like the ~AscensionResult~
specifies the increase as a percent increase of our current
multiplier, so i.e. at an ~ascMult~ = 21.5, ascending and achieving a
new ~ascMult~ of 22.5 is calculated as only a 1.04 ~ascResult~

Whereas at lower levels a change from ~ascmult~ 1 to 2 is a
~ascResult~ of 2 because it's doubling.

* Misc.

** Remove RAM naming from buy-servers

Change ~buy-servers.ts~ to not name servers with RAM amount.

It makes upgrading harder, always having to pass rename and having the
memory display that shows the amount of RAM makes it unnecessary.

** Refactor ~backdoor-notify~ to get servers from Discovery

Maybe? Would need a new API for getting _all_ servers.
